{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación multiclase\n",
    "\n",
    "## Introduction\n",
    "\n",
    "En este ejercicio se implementa la regresion one-vs-all y una red neuronal para reconocimiento de digitos.\n",
    "\n",
    "Antes de empezar la ejecución de las partes de codigo correspondienters a los ejercicios, se requiere importar todas las librerias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizado para la manipulación de directorios y rutas\n",
    "import os\n",
    "\n",
    "# Cálculo científico y vectorial para python\n",
    "import numpy as np\n",
    "\n",
    "# Libreria para graficos\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Modulo de optimizacion en scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# modulo para cargar archivos en formato MATLAB\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10497"
      ]
     },
     "execution_count": 2103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "#funcion para adaptar el dataset a mas de 10 000 datos.\n",
    "def csvAdapted(path, modifyColumns, dropColumns):\n",
    "    data = pd.read_csv(path, encoding='latin-1')\n",
    "\n",
    "    \n",
    "    columns = data.columns\n",
    "\n",
    "    for index in modifyColumns:\n",
    "        name = columns[index]\n",
    "        value = list( data[name].unique() )\n",
    "        data[name] = data[name].map( dict( zip( value,  [i for i in range( len(value) ) ] ) ) )\n",
    "\n",
    "    data = data.drop([columns[index] for index in dropColumns ], axis=1)\n",
    "    \n",
    "    data=data.fillna(0)\n",
    "\n",
    "    print(data.head())\n",
    "\n",
    "    return data.to_numpy()\n",
    "\n",
    "_data = csvAdapted(\"winequalityN.csv\", [], [0] )\n",
    "\n",
    "\n",
    "for index in range(len(_data)):\n",
    "    if( _data[index][11] >=0 and  _data[index][11] <=3):\n",
    "        _data[index][11]=0\n",
    "\n",
    "    if( _data[index][11] >=4 and  _data[index][11] <=7):\n",
    "        _data[index][11]=1\n",
    "\n",
    "    if( _data[index][11] >=8):\n",
    "        _data[index][11]=2\n",
    "\n",
    "\n",
    "dataGenerate = []\n",
    "\n",
    "for j in range(0,1):\n",
    "    for i in range(0, 4000 ):\n",
    "        aleatorio = random.randint(0,1)\n",
    "        _data_ = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "        _data_[0] = _data[i][0] + random.randint(-1,1)\n",
    "        _data_[1] = _data[i][1] + random.randint(-1,1)\n",
    "        _data_[2] = _data[i][2] + random.randint(-1,1)\n",
    "        _data_[3] = _data[i][3] + random.randint(-1,1)\n",
    "   \n",
    "        _data_[5] = _data[i][5] + random.randint(-1,1)\n",
    "        _data_[6] = _data[i][6] + random.randint(-1,1)\n",
    "        _data_[7] = _data[i][7] + random.randint(-1,1)\n",
    "        _data_[8] = _data[i][8] + random.randint(-1,1)\n",
    "        _data_[9] = _data[i][9] + random.randint(-1,1)\n",
    "        _data_[10] = _data[i][10] + random.randint(-1,1)\n",
    "        _data_[11] = _data[i][11] + random.randint(-1,1)\n",
    "\n",
    "        if aleatorio>0.5:\n",
    "            _data_[11] = _data[i][11] + 1\n",
    "        else:\n",
    "            _data_[11] = _data[i][11]\n",
    "        dataGenerate.append( _data_ )\n",
    "\n",
    "data =  np.append(_data,dataGenerate,axis= 0)\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usaremos de nuestro dataset la columna 12 que seria la calidad para clasificarla en 3 categorias, donde: 1 es 'baja calidad', 2 es 'media calidad', 3 es 'buena calidad'\n",
    "#3 etiquetas, de 1 a 3\n",
    "num_labels = 3\n",
    "#  datos de entrenamiento almacenados en los arreglos X, y , usando el 80% para el entrenamiento.\n",
    "X, y = data[:8000, [0,1,2,3,4,5,6,7,8,9,10] ], data[:8000,11]\n",
    "m = y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.    0.27  0.36 ...  3.    0.45  8.8 ]\n",
      " [ 6.3   0.3   0.34 ...  3.3   0.49  9.5 ]\n",
      " [ 8.1   0.28  0.4  ...  3.26  0.44 10.1 ]\n",
      " ...\n",
      " [ 8.4  -0.81 -0.51 ...  1.99 -0.68 12.  ]\n",
      " [ 8.3   1.2   1.49 ...  3.05  1.37  9.1 ]\n",
      " [ 5.6  -0.7   0.24 ...  2.13  1.36  8.2 ]]\n",
      "[1. 1. 1. ... 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula la sigmoide de z.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y \n",
    "    el gradiente del costo w.r.t. a los parámetros.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas \n",
    "        incluida la intercepcion\n",
    "        \n",
    "    X : array_like\n",
    "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de \n",
    "        caracteristicas (incluida la intercepcion).\n",
    "    \n",
    "    y : array_like\n",
    "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
    "    \n",
    "    lambda_ : float\n",
    "        Parametro de regularización. \n",
    "    \n",
    "    Devuelve\n",
    "    -------\n",
    "    J : float\n",
    "        El valor calculado para la funcion de costo regularizada. \n",
    "    \n",
    "    grad : array_like\n",
    "        Un vector de la forma (shape) (n, ) que es el gradiente de la \n",
    "        función de costo con respecto a theta, en los valores actuales de theta..\n",
    "    \"\"\"\n",
    "    # Inicializa algunos valores utiles\n",
    "    m = y.size\n",
    "    \n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    \n",
    "    grad = (1 / m) * (h - y).dot(X) \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo         : 3.085728\n",
      "Costo esperadot: 2.534819\n",
      "-----------------------\n",
      "Gradientes:\n",
      " [0.355376, -0.491709, 0.885979, 1.663668]\n",
      "Gradientes esperados:\n",
      " [0.146561, -0.548558, 0.724722, 1.398003]\n"
     ]
    }
   ],
   "source": [
    "J, grad = lrCostFunction(theta_t, X_t, y_t, lambda_t)\n",
    "\n",
    "print('Costo         : {:.6f}'.format(J))\n",
    "print('Costo esperadot: 2.534819')\n",
    "print('-----------------------')\n",
    "print('Gradientes:')\n",
    "print(' [{:.6f}, {:.6f}, {:.6f}, {:.6f}]'.format(*grad))\n",
    "print('Gradientes esperados:')\n",
    "print(' [0.146561, -0.548558, 0.724722, 1.398003]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "### 1.4 Clasificacion One-vs-all\n",
    "En esta parte del ejercicio, se implementará la clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados, uno para cada una de las clases $K$ en nuestro conjunto de datos. En el conjunto de datos de dígitos escritos a mano, $K = 10$, pero su código debería funcionar para cualquier valor de $K$.\n",
    "\n",
    "El argumento `y` de esta función es un vector de etiquetas de 0 a 9. Al entrenar el clasificador para la clase $k \\in \\{0, ..., K-1 \\} $, querrá un vector K-dimensional de etiquetas $y$, donde $y_j \\ in 0, 1$ indica si la instancia de entrenamiento $j ^ {th}$ pertenece a la clase $k$ $(y_j = 1)$, o si pertenece a una clase diferente $(y_j = 0)$.\n",
    "\n",
    "Además, se utiliza `optimize.minimize` de scipy para este ejercicio.\n",
    "<a id=\"oneVsAll\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "    \"\"\"\n",
    "    \n",
    "Entrena el numero de labels clasificadores de regresión logística y devuelve\n",
    "    cada uno de estos clasificadores en una matriz all_theta, donde el i-ésimo\n",
    "    fila de all_theta corresponde al clasificador para la etiqueta i.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    X : tipo_array\n",
    "        El conjunto de datos de entrada de forma (m x n). m es el número de\n",
    "        puntos de datos, y n es el número de entidades. Tenga en cuenta que nosotros\n",
    "        no asumimos que el término de intersección (o sesgo) está en X, sin embargo\n",
    "        proporcionamos el código a continuación para agregar el término de sesgo a X.\n",
    "    \n",
    "    y : tipo_array\n",
    "        Las etiquetas de datos. Un vector de forma (m, ).\n",
    "    \n",
    "    num_labels : entero\n",
    "        numero posible de etiquetas\n",
    "    \n",
    "    lambda_ : real\n",
    "        parametro regulador de la logistica\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    all_theta : tipo_array\n",
    "        los parámetros entrenados para la regresión logística para cada clase.\n",
    "        Esta es una matriz de forma (K x n+1) donde K es el número de clases\n",
    "        (es decir, `numlabels`) y n es el número de características sin el sesgo.\n",
    "    \"\"\"\n",
    "    # algunas variables utiles\n",
    "    m, n = X.shape\n",
    "    \n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 200}\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                                initial_theta, \n",
    "                                (X, (y == c), lambda_), \n",
    "                                jac=True, \n",
    "                                method='CG',\n",
    "                                options=options) \n",
    "        \n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h0/sdnxmh9s79j53gnv0s63splr0000gn/T/ipykernel_12431/1892987983.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
      "/var/folders/h0/sdnxmh9s79j53gnv0s63splr0000gn/T/ipykernel_12431/1892987983.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
      "/var/folders/h0/sdnxmh9s79j53gnv0s63splr0000gn/T/ipykernel_12431/1892987983.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50334303  0.15536474  0.98408475 -0.14658911 -0.06621669  0.15933694\n",
      "   0.03174221 -0.00996122 -0.14342038 -0.36327402 -0.65944584 -0.42922609]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]\n",
      " [-0.38695292 -0.18272553 -0.20134753  0.10762299 -0.01719408 -0.86497517\n",
      "  -0.00511143  0.00594607 -0.09760296 -0.48993693  0.02014062  0.08370154]]\n"
     ]
    }
   ],
   "source": [
    "#Aqui podemos probar diferentes parametros para el regulador de la logistica(lambda)\n",
    "lambda_ = 0.71\n",
    "\n",
    "\n",
    "\n",
    "all_theta = oneVsAll(X, y, num_labels, lambda_)\n",
    "print(all_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "#### 1.4.1 Prediccion One-vs-all\n",
    "\n",
    "Después de entrenar el clasificador de one-vs-all, se puede usarlo para predecir el dígito contenido en una imagen determinada. Para cada entrada, debe calcular la \"probabilidad\" de que pertenezca a cada clase utilizando los clasificadores de regresión logística entrenados. La función de predicción one-vs-all seleccionará la clase para la cual el clasificador de regresión logística correspondiente genera la probabilidad más alta y devolverá la etiqueta de clase (0, 1, ..., K-1) como la predicción para el ejemplo de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    \"\"\"\n",
    "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
    "    Tenga en cuenta que X contiene los ejemplos en filas. \n",
    "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase. \n",
    "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1] \n",
    "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    all_theta : tipo_array\n",
    "     \n",
    "        Los parámetros entrenados para la regresión logística para cada clase.\n",
    "        Esta es una matriz de forma (K x n+1) donde K es el número de clases\n",
    "        y n es el número de características sin el sesgo.\n",
    "    X : tipo_array\n",
    "        Puntos de datos para predecir sus etiquetas. Esta es una matriz de forma\n",
    "        (m x n) donde m es el número de puntos de datos para predecir, y n es el número\n",
    "        de características sin el término de sesgo. Tenga en cuenta que agregamos el término de sesgo para X en\n",
    "        esta función\n",
    "    \n",
    "    Devuelve\n",
    "    -------\n",
    "    p : array_like\n",
    "        Las predicciones para cada punto de datos en X. Este es un vector de forma (m, ).\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # Aggrega ones a la matriz de datos X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que haya terminado, se llama a la función `predictOneVsAll` usando el valor aprendido de $\\theta$. Debería apreciarse que la precisión del conjunto de entrenamiento es de aproximadamente 95,1% (es decir, clasifica correctamente el 95,1% de los ejemplos del conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Precision del conjuto de entrenamiento: 48.14%\n"
     ]
    }
   ],
   "source": [
    "#ingresamos el 20% de datos restantes de nuestro data set para usarlos como comparacion\n",
    "XPrueba = data[8000:,[0,1,2,3,4,5,6,7,8,9,10] ].copy()\n",
    "\n",
    "pred = predictOneVsAll(all_theta, XPrueba)\n",
    "# imprimimos la prediccion y la precision del conjunto de entrenamiento\n",
    "print(pred)\n",
    "\n",
    "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == data[8000:,11]) * 100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ae5a986935bf018834bd5c275c5a6b98b447801b0a0e976283c7009c88d42c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
